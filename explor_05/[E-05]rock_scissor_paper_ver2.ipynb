{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002fac06",
   "metadata": {},
   "source": [
    "## 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d83606",
   "metadata": {},
   "source": [
    "### [ 주요 내용]\n",
    "\n",
    "1. Exploration 내용 따라하기 (가위 바위 보 데이터 기준)\n",
    "  - 데이터 준비 : (Train) 가위(100), 바위(100), 보(100) / (Test) 가위(100), 바위(100), 보(100)\n",
    "  - 모델 적용 : Conv2D - MaxPooling - Conv2D - MaxPooling - Flatten\n",
    "  - 학습 및 평가 : Accuracy 54%\n",
    "  \n",
    "2. 모델 개선\n",
    "  - 데이터 수 추가 : Tensorflow의 ImageDataGenerator 모듈을 이용한 기존 이미지 부풀리기 --> 총 3,190개 파일 (Train 자료)\n",
    "  - 모델 파라메터 변경 : Layer층 노드 증가 및 epoch 수 증가\n",
    "  - 학습 및 평가 : Accuracy 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d656e",
   "metadata": {},
   "source": [
    "### (1) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be59c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 모듈 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854e2686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장.\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "   \n",
    "    # print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "# 이미지가 저장된 각 디렉토리 모든 jpg 파일에 적용\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdc5d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# Train 데이터 읽어들임\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8ed29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data 내용 sample 확인\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16787f53",
   "metadata": {},
   "source": [
    "### (2) 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f437fbe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설계\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c46de",
   "metadata": {},
   "source": [
    "### (3) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55703f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 37ms/step - loss: 1.1149 - accuracy: 0.2867\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 1.0934 - accuracy: 0.4967\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 1.0817 - accuracy: 0.4433\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 1.0659 - accuracy: 0.5067\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 1.0356 - accuracy: 0.6500\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.9830 - accuracy: 0.7100\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.8950 - accuracy: 0.7367\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.9078 - accuracy: 0.5833\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.7728 - accuracy: 0.7600\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.6846 - accuracy: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d983ba1f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 전체 10번 반복학습\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44d806",
   "metadata": {},
   "source": [
    "### (4) 테스트(평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67a76ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 만들기 - resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31599efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 불러오기\n",
    "\n",
    "def load_test_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4886a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.2426 - accuracy: 0.5400\n",
      "test_loss: 1.242630958557129 \n",
      "test_accuracy: 0.5400000214576721\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 모델 평가\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018507e6",
   "metadata": {},
   "source": [
    "### (5) 모델 개선하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709f7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 부풀리기는 https://pyimagesearch.com 블로거 참조\n",
    "# 훈련데이터 데이터 부풀리기 위한 모듈 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718db599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존이미지로부터 생성할 이미지의 변형 및 반전 범위 지정\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "rotation_range=30,\n",
    "zoom_range=0.2,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4381c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가위 이미지 부풀리기 완료!\n"
     ]
    }
   ],
   "source": [
    "# 기존 파일마다 10개의 변형 이미지 생성\n",
    "\n",
    "def make_images(image_path, save_path):\n",
    "\n",
    "    images=glob.glob(image_path + \"/*.jpg\")  \n",
    "\n",
    "    for img in images:\n",
    "        image = load_img(img)\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        imageGen = aug.flow(image, batch_size=1, save_to_dir=save_path,\n",
    "        save_prefix=\"g\", save_format=\"jpg\")\n",
    "\n",
    "        total = 0\n",
    "        for image in imageGen:\n",
    "            total += 1\n",
    "            if total == 10:\n",
    "                break\n",
    "    \n",
    "# 보 이미지가 저장된 각 디렉토리 모든 jpg 파일에 적용\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "save_path = os.getenv(\"HOME\") + \"/aiffel/LMS/paper\"\n",
    "\n",
    "make_images(image_path,save_path)\n",
    "\n",
    "print(\"보 이미지 부풀리기 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 각 디렉토리 모든 jpg 파일에 적용\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "save_path = os.getenv(\"HOME\") + \"/aiffel/LMS/rock\"\n",
    "\n",
    "make_images(image_path,save_path)\n",
    "\n",
    "print(\"가위 이미지 부풀리기 완료!\")\n",
    "\n",
    "# 가위 이미지가 저장된 각 디렉토리 모든 jpg 파일에 적용\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "save_path = os.getenv(\"HOME\") + \"/aiffel/LMS/scissor\"\n",
    "\n",
    "make_images(image_path,save_path)\n",
    "\n",
    "print(\"가위 이미지 부풀리기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f17ebdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "1062  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "1060  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 추가된 훈련데이터로 학습진행: 하이퍼파라미터 변경, epoch수 증가 포함\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "   \n",
    "    # print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "# 이미지가 저장된 각 디렉토리 모든 jpg 파일에 적용\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60ca80b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3190 입니다.\n",
      "x_train shape: (3190, 28, 28, 3)\n",
      "y_train shape: (3190,)\n"
     ]
    }
   ],
   "source": [
    "# Train 데이터 읽어들임\n",
    "\n",
    "def load_data(img_path, number_of_data=3190):  # 가위바위보 이미지 개수 총합\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "808b3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 224,707\n",
      "Trainable params: 224,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설계 : 32-64-128 개로 조정\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2b50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.0761 - accuracy: 0.3856\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.9396 - accuracy: 0.5542\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.8205 - accuracy: 0.6420\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.6950 - accuracy: 0.6997\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.6090 - accuracy: 0.7480\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.5392 - accuracy: 0.7906\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.4557 - accuracy: 0.8141\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.3712 - accuracy: 0.8596\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.3232 - accuracy: 0.8768\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2706 - accuracy: 0.8972\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2310 - accuracy: 0.9172\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2176 - accuracy: 0.9226\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2061 - accuracy: 0.9197\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.1579 - accuracy: 0.9470\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.1259 - accuracy: 0.9633\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.1201 - accuracy: 0.9618\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.1009 - accuracy: 0.9702\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.0827 - accuracy: 0.9796\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.0745 - accuracy: 0.9765\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.0655 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec1305c550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 전체 20번 반복학습: epochs 수 증가\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d066c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 만들기 - resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "075dc4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 불러오기\n",
    "\n",
    "def load_test_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "469d834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9534 - accuracy: 0.7467\n",
      "test_loss: 0.9533736109733582 \n",
      "test_accuracy: 0.746666669845581\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 모델 평가\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513ea43",
   "metadata": {},
   "source": [
    "## [ 회 고 ]\n",
    "\n",
    " - 훈련 데이터 대비 테스트 데이터 생성 배경이 다를 경우 범용적인 적용이 쉽지 않음을 알 수 있었음\n",
    " - 훈련 데이터 확보의 한가지 방법으로 Tensorflow가 제공하는 ImageDataGenerator 모듈 활용은 좋은 경험이었음\n",
    " - 심층 신경망 모델형성은 일종의 요리를 하는 것 같다는 생각이 들었음\n",
    "    - 좋은 재료를 마련해야 하고, 어떤 도구로 조리 순서의 조합을 어떻게 해야 좋은 음식이 나오는지의 recipe를 마련하는 작업\n",
    "    - 성과가 입증된 모델은 널리 사용될 수 있다(transfer learning)\n",
    " - 이미지와 파일을 다루는 기법을 좀 더 알아야 할 것 같음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
